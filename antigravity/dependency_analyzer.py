"""
Antigravity æ·±åº¦ä¾èµ–åˆ†æå™¨
Deep Dependency Analyzer

åŠŸèƒ½ / Features:
- AST è§£æ import è¯­å¥ / Parse import statements using AST
- æ„å»ºé¡¹ç›®ä¾èµ–å›¾ / Build project dependency graph
- æœ€å°ä¸Šä¸‹æ–‡ç®—æ³• / Minimal context algorithm
- æ”¯æŒç›¸å¯¹å¯¼å…¥ / Support relative imports
"""

import ast
import os
import json
from typing import Dict, List, Set, Optional
from pathlib import Path


class DependencyAnalyzer:
    """
    æ–‡ä»¶ä¾èµ–å…³ç³»åˆ†æå™¨
    File Dependency Analyzer
    
    é€šè¿‡ AST è§£ææ„å»ºé¡¹ç›®çº§çŸ¥è¯†å›¾è°±,è¯†åˆ«æ–‡ä»¶é—´çš„è°ƒç”¨é“¾
    Build project-level knowledge graph through AST parsing
    """
    
    def __init__(self, project_root: str):
        self.project_root = os.path.abspath(project_root)
        self.dependency_graph = {}  # {file: [dependencies]}
        self.reverse_graph = {}     # {file: [dependents]}
        self._cache = {}            # ç¼“å­˜å·²è§£æçš„æ–‡ä»¶
    
    def analyze_file(self, file_path: str) -> Set[str]:
        """
        åˆ†æå•ä¸ªæ–‡ä»¶çš„ä¾èµ–
        Analyze dependencies of a single file
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„ (ç›¸å¯¹äº project_root)
        
        Returns:
            Set of file paths this file depends on
        """
        # æ£€æŸ¥ç¼“å­˜
        if file_path in self._cache:
            return self._cache[file_path]
        
        dependencies = set()
        full_path = os.path.join(self.project_root, file_path)
        
        if not os.path.exists(full_path):
            return dependencies
        
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                source = f.read()
            
            tree = ast.parse(source, filename=file_path)
            
            for node in ast.walk(tree):
                # å¤„ç† import xxx
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        dep_file = self._resolve_import(alias.name, file_path)
                        if dep_file:
                            dependencies.add(dep_file)
                
                # å¤„ç† from xxx import yyy
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        # å¤„ç†ç›¸å¯¹å¯¼å…¥ (from .utils import x)
                        if node.level > 0:
                            dep_file = self._resolve_relative_import(
                                node.module, 
                                node.level, 
                                file_path
                            )
                        else:
                            dep_file = self._resolve_import(node.module, file_path)
                        
                        if dep_file:
                            dependencies.add(dep_file)
        
        except SyntaxError as e:
            print(f"âš ï¸ Syntax error in {file_path}: {e}")
        except Exception as e:
            print(f"âš ï¸ Failed to analyze {file_path}: {e}")
        
        # ç¼“å­˜ç»“æœ
        self._cache[file_path] = dependencies
        return dependencies
    
    def _resolve_import(self, module_name: str, current_file: str) -> Optional[str]:
        """
        å°† import è¯­å¥è§£æä¸ºå®é™…æ–‡ä»¶è·¯å¾„
        Resolve import statement to actual file path
        
        Example:
            "antigravity.utils" -> "antigravity/utils.py"
            "antigravity.api.handler" -> "antigravity/api/handler.py"
        """
        # è½¬æ¢æ¨¡å—åä¸ºè·¯å¾„
        path_parts = module_name.split('.')
        
        # å°è¯•å¤šç§å¯èƒ½çš„è·¯å¾„
        candidates = [
            os.path.join(*path_parts) + '.py',
            os.path.join(*path_parts, '__init__.py'),
        ]
        
        for candidate in candidates:
            full_path = os.path.join(self.project_root, candidate)
            if os.path.exists(full_path):
                return candidate
        
        return None
    
    def _resolve_relative_import(
        self, 
        module_name: Optional[str], 
        level: int, 
        current_file: str
    ) -> Optional[str]:
        """
        è§£æç›¸å¯¹å¯¼å…¥
        Resolve relative import
        
        Example:
            from . import utils (level=1, module=None)
            from ..utils import x (level=2, module="utils")
        
        Args:
            module_name: æ¨¡å—å (å¯èƒ½ä¸º None)
            level: ç›¸å¯¹å±‚çº§ (. = 1, .. = 2)
            current_file: å½“å‰æ–‡ä»¶è·¯å¾„
        
        Returns:
            è§£æåçš„æ–‡ä»¶è·¯å¾„
        """
        # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
        current_dir = os.path.dirname(current_file)
        
        # å‘ä¸Šå›æº¯ level å±‚
        for _ in range(level):
            current_dir = os.path.dirname(current_dir)
        
        # å¦‚æœæœ‰æ¨¡å—å,æ‹¼æ¥è·¯å¾„
        if module_name:
            path_parts = module_name.split('.')
            target_path = os.path.join(current_dir, *path_parts)
        else:
            target_path = current_dir
        
        # å°è¯•å¤šç§å¯èƒ½
        candidates = [
            target_path + '.py',
            os.path.join(target_path, '__init__.py'),
        ]
        
        for candidate in candidates:
            if os.path.exists(os.path.join(self.project_root, candidate)):
                return os.path.normpath(candidate).replace('\\', '/')
        
        return None
    
    def build_dependency_graph(self, target_files: Optional[List[str]] = None):
        """
        æ„å»ºå®Œæ•´çš„ä¾èµ–å…³ç³»å›¾
        Build complete dependency graph
        
        Args:
            target_files: å¦‚æœæŒ‡å®š,åªåˆ†æè¿™äº›æ–‡ä»¶;å¦åˆ™åˆ†ææ•´ä¸ªé¡¹ç›®
        """
        if target_files is None:
            # æ‰«ææ•´ä¸ªé¡¹ç›®
            target_files = self._scan_project()
        
        print(f"ğŸ” Analyzing {len(target_files)} files...")
        
        # æ„å»ºæ­£å‘ä¾èµ–å›¾
        for file_path in target_files:
            deps = self.analyze_file(file_path)
            self.dependency_graph[file_path] = list(deps)
        
        # æ„å»ºåå‘ä¾èµ–å›¾
        self.reverse_graph = {}
        for file, deps in self.dependency_graph.items():
            for dep in deps:
                if dep not in self.reverse_graph:
                    self.reverse_graph[dep] = []
                self.reverse_graph[dep].append(file)
        
        print(f"âœ… Dependency graph built: {len(self.dependency_graph)} nodes")
    
    def get_minimal_context(
        self, 
        target_file: str, 
        max_depth: int = 2
    ) -> Set[str]:
        """
        è·å–æœ€å°ä¸Šä¸‹æ–‡é›†åˆ (æ‰‹æœ¯çº§ç²¾å‡†å®šä½)
        Get minimal context set for a target file
        
        åŒ…æ‹¬:
        1. ç›®æ ‡æ–‡ä»¶æœ¬èº«
        2. ç›´æ¥ä¾èµ– (imports)
        3. ç›´æ¥è¢«ä¾èµ–è€… (imported by)
        4. é€’å½’åˆ°æŒ‡å®šæ·±åº¦
        
        Args:
            target_file: ç›®æ ‡æ–‡ä»¶è·¯å¾„
            max_depth: æœ€å¤§é€’å½’æ·±åº¦ (é»˜è®¤ 2,é˜²æ­¢å¾ªç¯ä¾èµ–)
        
        Returns:
            Set of file paths in minimal context
        """
        context = set()
        visited = set()
        
        def dfs(file, depth, direction="both"):
            """
            DFS éå†ä¾èµ–å›¾
            
            Args:
                direction: "forward" (åªçœ‹ä¾èµ–), "backward" (åªçœ‹è¢«ä¾èµ–), "both"
            """
            if depth > max_depth or file in visited:
                return
            
            visited.add(file)
            context.add(file)
            
            # æ·»åŠ ä¾èµ– (forward)
            if direction in ["forward", "both"]:
                for dep in self.dependency_graph.get(file, []):
                    dfs(dep, depth + 1, "forward")
            
            # æ·»åŠ è¢«ä¾èµ–è€… (backward)
            if direction in ["backward", "both"]:
                for dependent in self.reverse_graph.get(file, []):
                    dfs(dependent, depth + 1, "backward")
        
        dfs(target_file, 0)
        
        print(f"ğŸ“Š Minimal context for {target_file}: {len(context)} files")
        return context
    
    def _scan_project(self) -> List[str]:
        """
        æ‰«æé¡¹ç›®ä¸­æ‰€æœ‰ Python æ–‡ä»¶
        Scan all Python files in project
        """
        python_files = []
        
        # å¿½ç•¥çš„ç›®å½•
        ignore_dirs = {
            '.git', '__pycache__', 'venv', '.venv', 
            'node_modules', '.pytest_cache', 'dist', 'build',
            '.gemini'  # å¿½ç•¥ Antigravity è‡ªå·±çš„å·¥ä½œç›®å½•
        }
        
        for root, dirs, files in os.walk(self.project_root):
            # è¿‡æ»¤å¿½ç•¥çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in ignore_dirs]
            
            for file in files:
                if file.endswith('.py'):
                    full_path = os.path.join(root, file)
                    rel_path = os.path.relpath(full_path, self.project_root)
                    python_files.append(rel_path.replace('\\', '/'))
        
        return python_files
    
    def export_graph(self, output_file: str = "dependency_graph.json"):
        """
        å¯¼å‡ºä¾èµ–å…³ç³»å›¾ä¸º JSON
        Export dependency graph to JSON
        """
        graph_data = {
            "dependencies": self.dependency_graph,
            "reverse_dependencies": self.reverse_graph,
            "stats": {
                "total_files": len(self.dependency_graph),
                "total_edges": sum(len(deps) for deps in self.dependency_graph.values())
            }
        }
        
        output_path = os.path.join(self.project_root, output_file)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(graph_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Dependency graph exported to {output_file}")
        return output_path
    
    def get_dependency_chain(self, from_file: str, to_file: str) -> Optional[List[str]]:
        """
        è·å–ä¸¤ä¸ªæ–‡ä»¶ä¹‹é—´çš„ä¾èµ–é“¾
        Get dependency chain between two files
        
        Args:
            from_file: èµ·å§‹æ–‡ä»¶
            to_file: ç›®æ ‡æ–‡ä»¶
        
        Returns:
            ä¾èµ–é“¾è·¯å¾„åˆ—è¡¨,å¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        # BFS æŸ¥æ‰¾æœ€çŸ­è·¯å¾„
        from collections import deque
        
        queue = deque([(from_file, [from_file])])
        visited = {from_file}
        
        while queue:
            current, path = queue.popleft()
            
            if current == to_file:
                return path
            
            for dep in self.dependency_graph.get(current, []):
                if dep not in visited:
                    visited.add(dep)
                    queue.append((dep, path + [dep]))
        
        return None
    
    def invalidate_cache(self, file_path: str):
        """
        ä½¿ç¼“å­˜å¤±æ•ˆ (å½“æ–‡ä»¶å˜æ›´æ—¶è°ƒç”¨)
        Invalidate cache when file changes
        """
        if file_path in self._cache:
            del self._cache[file_path]
            print(f"ğŸ”„ Cache invalidated for {file_path}")


if __name__ == "__main__":
    # æµ‹è¯•ä¾èµ–åˆ†æå™¨
    print("ğŸ§ª Testing Dependency Analyzer...")
    
    analyzer = DependencyAnalyzer(".")
    
    # æ„å»ºä¾èµ–å›¾
    analyzer.build_dependency_graph()
    
    # å¯¼å‡ºä¾èµ–å›¾
    analyzer.export_graph()
    
    # æµ‹è¯•æœ€å°ä¸Šä¸‹æ–‡
    if analyzer.dependency_graph:
        test_file = list(analyzer.dependency_graph.keys())[0]
        context = analyzer.get_minimal_context(test_file)
        print(f"\nğŸ“‹ Minimal context for {test_file}:")
        for file in sorted(context):
            print(f"  - {file}")
