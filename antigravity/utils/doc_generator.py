"""
Automatic Documentation Generator
Generates professional README.md and requirements.txt from project code
"""

from pathlib import Path
from typing import Set, List
import ast
import re


class DocGenerator:
    """Automatic documentation and dependency generator"""
    
    def __init__(self, project_root: Path):
        self.root = Path(project_root).resolve()
        self.project_name = self.root.name
    
    def generate_readme(self) -> str:
        """Generate professional README.md"""
        # Extract components
        description = self._extract_description()
        structure = self._generate_file_tree()
        features = self._extract_features()
        
        # Build README
        readme = f"""# {self.project_name}

## ðŸ“‹ Description

{description}

## âœ¨ Features

{features}

## ðŸ“ Project Structure

```
{structure}
```

## ðŸš€ Installation

```bash
# Install dependencies
pip install -r requirements.txt
```

## ðŸ’» Usage

```python
# TODO: Add usage examples
# Import main module
from {self.project_name.lower()} import main

# Run application
main()
```

## ðŸ§ª Testing

```bash
# Run tests
pytest tests/
```

## ðŸ“¦ Dependencies

See `requirements.txt` for full list of dependencies.

## ðŸ¤– Development

This project was scaffolded and managed using **Antigravity** - an AI-powered development automation system.

### Project Health

Run Vibe Check to assess project health:
```bash
python -m antigravity.vibe_check
```

## ðŸ“„ License

MIT License

---

*Generated automatically by Antigravity DocGenerator*
"""
        return readme
    
    def generate_requirements(self) -> str:
        """Generate requirements.txt from code imports"""
        imports = self._scan_imports()
        third_party = self._filter_third_party(imports)
        
        if not third_party:
            return "# No third-party dependencies detected\n"
        
        # Format as requirements.txt
        requirements = []
        requirements.append("# Auto-generated by Antigravity DocGenerator")
        requirements.append("# Project: " + self.project_name)
        requirements.append("")
        
        for package in sorted(third_party):
            requirements.append(package)
        
        return '\n'.join(requirements)
    
    def _extract_description(self) -> str:
        """Extract description from PLAN.md"""
        plan_path = self.root / "PLAN.md"
        
        if not plan_path.exists():
            return f"A Python project managed by Antigravity."
        
        content = plan_path.read_text(encoding='utf-8')
        lines = content.split('\n')
        
        # Try to find first meaningful paragraph
        description_lines = []
        in_paragraph = False
        
        for line in lines:
            stripped = line.strip()
            
            # Skip headers
            if stripped.startswith('#'):
                continue
            
            # Skip empty lines before paragraph starts
            if not stripped and not in_paragraph:
                continue
            
            # Start collecting paragraph
            if stripped and not in_paragraph:
                in_paragraph = True
            
            # Add line to description
            if in_paragraph:
                if not stripped:
                    break  # End of paragraph
                description_lines.append(stripped)
        
        description = ' '.join(description_lines)
        
        # Limit length
        if len(description) > 500:
            description = description[:497] + "..."
        
        return description if description else "A Python project managed by Antigravity."
    
    def _extract_features(self) -> str:
        """Extract features from PLAN.md or code"""
        plan_path = self.root / "PLAN.md"
        
        if not plan_path.exists():
            return "- Feature extraction requires PLAN.md"
        
        content = plan_path.read_text(encoding='utf-8')
        
        # Look for feature sections
        features = []
        in_features = False
        
        for line in content.split('\n'):
            stripped = line.strip()
            
            # Detect feature section
            if re.search(r'#.*åŠŸèƒ½|#.*feature', stripped, re.I):
                in_features = True
                continue
            
            # Exit feature section on next header
            if in_features and stripped.startswith('#'):
                break
            
            # Collect bullet points
            if in_features and (stripped.startswith('-') or stripped.startswith('*')):
                features.append(stripped)
        
        if features:
            return '\n'.join(features[:10])  # Limit to 10 features
        else:
            return "- Automated project scaffolding\n- AI-powered code generation\n- Comprehensive testing"
    
    def _generate_file_tree(self) -> str:
        """Generate ASCII file tree"""
        tree_lines = []
        
        def walk_dir(path: Path, prefix: str = "", depth: int = 0):
            if depth > 4:  # Limit depth
                return
            
            try:
                items = sorted(path.iterdir(), key=lambda x: (not x.is_dir(), x.name))
            except PermissionError:
                return
            
            # Filter out common ignore patterns
            items = [
                item for item in items
                if not item.name.startswith('.')
                and item.name not in ['__pycache__', 'node_modules', 'venv', '.git']
            ]
            
            for i, item in enumerate(items[:30]):  # Limit items
                is_last = i == len(items) - 1
                connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                
                if item.is_dir():
                    tree_lines.append(f"{prefix}{connector}{item.name}/")
                    extension = "    " if is_last else "â”‚   "
                    walk_dir(item, prefix + extension, depth + 1)
                else:
                    tree_lines.append(f"{prefix}{connector}{item.name}")
        
        tree_lines.append(self.project_name + "/")
        walk_dir(self.root)
        
        return '\n'.join(tree_lines)
    
    def _scan_imports(self) -> Set[str]:
        """Scan all Python files for imports"""
        imports = set()
        
        for py_file in self.root.rglob("*.py"):
            try:
                content = py_file.read_text(encoding='utf-8')
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            # Get top-level package
                            package = alias.name.split('.')[0]
                            imports.add(package)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            # Get top-level package
                            package = node.module.split('.')[0]
                            imports.add(package)
            except:
                continue
        
        return imports
    
    def _filter_third_party(self, imports: Set[str]) -> Set[str]:
        """Filter out standard library and local imports"""
        # Python standard library (common modules)
        stdlib = {
            'abc', 'argparse', 'ast', 'asyncio', 'base64', 'collections',
            'concurrent', 'contextlib', 'copy', 'csv', 'dataclasses',
            'datetime', 'decimal', 'enum', 'functools', 'glob', 'hashlib',
            'heapq', 'html', 'http', 'io', 'itertools', 'json', 'logging',
            'math', 'multiprocessing', 'operator', 'os', 'pathlib', 'pickle',
            'platform', 'queue', 'random', 're', 'shutil', 'signal', 'socket',
            'sqlite3', 'string', 'struct', 'subprocess', 'sys', 'tempfile',
            'threading', 'time', 'traceback', 'typing', 'unittest', 'urllib',
            'uuid', 'warnings', 'weakref', 'xml', 'zipfile'
        }
        
        # Filter out stdlib and local modules
        third_party = set()
        
        for imp in imports:
            # Skip if in stdlib
            if imp in stdlib:
                continue
            
            # Skip if looks like local module (starts with project name)
            if imp.lower() == self.project_name.lower():
                continue
            
            # Skip common local patterns
            if imp in ['main', 'config', 'utils', 'helpers', 'tests']:
                continue
            
            third_party.add(imp)
        
        return third_party
