"""
Antigravity å˜æ›´æ£€æµ‹å™¨
Change Detector

åŠŸèƒ½ / Features:
- æ–‡ä»¶å“ˆå¸Œè®¡ç®— / File hash calculation (MD5)
- å¿«ç…§ä¿å­˜/åŠ è½½ / Snapshot save/load
- æ£€æµ‹å˜æ›´/æ–°å¢/åˆ é™¤ / Detect changed/new/deleted files
- å¢é‡åŒæ­¥ç­–ç•¥ / Incremental sync strategy
"""

import hashlib
import json
import os
from typing import Dict, List, Set, Optional
from datetime import datetime


class ChangeDetector:
    """
    æ–‡ä»¶å˜æ›´æ£€æµ‹å™¨
    File Change Detector
    
    é€šè¿‡å“ˆå¸Œå¯¹æ¯”å®ç°å¢é‡åŒæ­¥,å‡å°‘ API è°ƒç”¨æˆæœ¬
    Implement incremental sync through hash comparison to reduce API costs
    """
    
    def __init__(self, project_root: str):
        self.project_root = os.path.abspath(project_root)
        self.snapshot_file = os.path.join(project_root, ".antigravity_snapshot.json")
        self.current_snapshot = {}
        self.previous_snapshot = self._load_snapshot()
    
    def _compute_hash(self, file_path: str) -> str:
        """
        è®¡ç®—æ–‡ä»¶å“ˆå¸Œ (MD5)
        Compute file hash using MD5
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„ (ç›¸å¯¹äº project_root)
        
        Returns:
            MD5 å“ˆå¸Œå­—ç¬¦ä¸²
        """
        full_path = os.path.join(self.project_root, file_path)
        
        try:
            with open(full_path, 'rb') as f:
                file_hash = hashlib.md5()
                # åˆ†å—è¯»å–,é¿å…å¤§æ–‡ä»¶å†…å­˜æº¢å‡º
                for chunk in iter(lambda: f.read(4096), b""):
                    file_hash.update(chunk)
                return file_hash.hexdigest()
        except FileNotFoundError:
            return ""
        except Exception as e:
            print(f"âš ï¸ Failed to hash {file_path}: {e}")
            return ""
    
    def _load_snapshot(self) -> Dict[str, str]:
        """
        åŠ è½½ä¸Šæ¬¡çš„å¿«ç…§
        Load previous snapshot
        
        Returns:
            {file_path: hash} å­—å…¸
        """
        if os.path.exists(self.snapshot_file):
            try:
                with open(self.snapshot_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # å…¼å®¹æ—§æ ¼å¼å’Œæ–°æ ¼å¼
                    if isinstance(data, dict) and "snapshots" in data:
                        return data["snapshots"]
                    return data
            except Exception as e:
                print(f"âš ï¸ Failed to load snapshot: {e}")
                return {}
        return {}
    
    def save_snapshot(self, metadata: Optional[Dict] = None):
        """
        ä¿å­˜å½“å‰å¿«ç…§
        Save current snapshot
        
        Args:
            metadata: å¯é€‰çš„å…ƒæ•°æ® (å¦‚æ—¶é—´æˆ³, æäº¤ä¿¡æ¯ç­‰)
        """
        snapshot_data = {
            "snapshots": self.current_snapshot,
            "metadata": metadata or {},
            "timestamp": datetime.now().isoformat(),
            "total_files": len(self.current_snapshot)
        }
        
        try:
            with open(self.snapshot_file, 'w', encoding='utf-8') as f:
                json.dump(snapshot_data, f, indent=2, ensure_ascii=False)
            print(f"âœ… Snapshot saved: {len(self.current_snapshot)} files")
        except Exception as e:
            print(f"âš ï¸ Failed to save snapshot: {e}")
    
    def scan_files(self, file_paths: List[str]):
        """
        æ‰«ææ–‡ä»¶å¹¶æ›´æ–°å¿«ç…§
        Scan files and update snapshot
        
        Args:
            file_paths: è¦æ‰«æçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ (ç›¸å¯¹äº project_root)
        """
        print(f"ğŸ” Scanning {len(file_paths)} files...")
        
        # v1.0.1 Hotfix: Binary Exclusion
        binary_extensions = {'.db', '.pyc', '.bin', '.exe', '.dll', '.so', '.dylib', '.png', '.jpg', '.jpeg', '.gif', '.ico'}
        
        for file_path in file_paths:
            # Check extension
            ext = os.path.splitext(file_path)[1].lower()
            if ext in binary_extensions:
                continue
                
            file_hash = self._compute_hash(file_path)
            if file_hash:  # åªè®°å½•æˆåŠŸè®¡ç®—å“ˆå¸Œçš„æ–‡ä»¶
                self.current_snapshot[file_path] = file_hash
        
        print(f"âœ… Scan complete: {len(self.current_snapshot)} files in snapshot")
    
    def get_changed_files(self) -> Set[str]:
        """
        è·å–å˜æ›´çš„æ–‡ä»¶ (å†…å®¹å˜åŒ–)
        Get changed files (content modified)
        
        Returns:
            å˜æ›´æ–‡ä»¶è·¯å¾„é›†åˆ
        """
        changed = set()
        
        for file, current_hash in self.current_snapshot.items():
            previous_hash = self.previous_snapshot.get(file)
            
            # æ–‡ä»¶å­˜åœ¨äºä¸Šæ¬¡å¿«ç…§,ä½†å“ˆå¸Œä¸åŒ
            if previous_hash and previous_hash != current_hash:
                changed.add(file)
        
        return changed
    
    def get_new_files(self) -> Set[str]:
        """
        è·å–æ–°å¢çš„æ–‡ä»¶
        Get newly added files
        
        Returns:
            æ–°å¢æ–‡ä»¶è·¯å¾„é›†åˆ
        """
        current_files = set(self.current_snapshot.keys())
        previous_files = set(self.previous_snapshot.keys())
        
        return current_files - previous_files
    
    def get_deleted_files(self) -> Set[str]:
        """
        è·å–åˆ é™¤çš„æ–‡ä»¶
        Get deleted files
        
        Returns:
            åˆ é™¤æ–‡ä»¶è·¯å¾„é›†åˆ
        """
        current_files = set(self.current_snapshot.keys())
        previous_files = set(self.previous_snapshot.keys())
        
        return previous_files - current_files
    
    def get_unchanged_files(self) -> Set[str]:
        """
        è·å–æœªå˜æ›´çš„æ–‡ä»¶
        Get unchanged files
        
        Returns:
            æœªå˜æ›´æ–‡ä»¶è·¯å¾„é›†åˆ
        """
        unchanged = set()
        
        for file, current_hash in self.current_snapshot.items():
            previous_hash = self.previous_snapshot.get(file)
            
            # æ–‡ä»¶å­˜åœ¨äºä¸Šæ¬¡å¿«ç…§,ä¸”å“ˆå¸Œç›¸åŒ
            if previous_hash and previous_hash == current_hash:
                unchanged.add(file)
        
        return unchanged
    
    def has_changes(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å˜æ›´
        Check if there are any changes
        
        Returns:
            True if there are changes, False otherwise
        """
        changed = self.get_changed_files()
        new = self.get_new_files()
        deleted = self.get_deleted_files()
        
        return len(changed) > 0 or len(new) > 0 or len(deleted) > 0
    
    def get_change_summary(self) -> Dict[str, any]:
        """
        è·å–å˜æ›´æ‘˜è¦
        Get change summary
        
        Returns:
            å˜æ›´æ‘˜è¦å­—å…¸
        """
        changed = self.get_changed_files()
        new = self.get_new_files()
        deleted = self.get_deleted_files()
        unchanged = self.get_unchanged_files()
        
        return {
            "changed": list(changed),
            "new": list(new),
            "deleted": list(deleted),
            "unchanged": list(unchanged),
            "total_changes": len(changed) + len(new) + len(deleted),
            "total_files": len(self.current_snapshot)
        }
    
    def should_use_incremental_sync(self, threshold: int = 3) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨å¢é‡åŒæ­¥
        Determine if incremental sync should be used
        
        Args:
            threshold: å˜æ›´æ–‡ä»¶æ•°é˜ˆå€¼,å°äºç­‰äºæ­¤å€¼ä½¿ç”¨å¢é‡åŒæ­¥
        
        Returns:
            True if incremental sync is recommended
        """
        changed = self.get_changed_files()
        new = self.get_new_files()
        
        total_changes = len(changed) + len(new)
        
        return total_changes > 0 and total_changes <= threshold
    
    def is_file_changed(self, file_path: str) -> bool:
        """
        æ£€æŸ¥å•ä¸ªæ–‡ä»¶æ˜¯å¦å˜æ›´
        Check if a single file has changed
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„ (ç›¸å¯¹äº project_root)
        
        Returns:
            True if file changed, False otherwise
        """
        current_hash = self._compute_hash(file_path)
        previous_hash = self.previous_snapshot.get(file_path)
        
        return current_hash != previous_hash
    
    def reset_snapshot(self):
        """
        é‡ç½®å¿«ç…§ (æ¸…ç©ºå½“å‰å’Œå†å²å¿«ç…§)
        Reset snapshot (clear current and previous)
        """
        self.current_snapshot = {}
        self.previous_snapshot = {}
        
        if os.path.exists(self.snapshot_file):
            os.remove(self.snapshot_file)
            print("âœ… Snapshot reset")


if __name__ == "__main__":
    # æµ‹è¯•å˜æ›´æ£€æµ‹å™¨
    print("ğŸ§ª Testing Change Detector...")
    
    detector = ChangeDetector(".")
    
    # æ‰«æé¡¹ç›®æ–‡ä»¶
    test_files = [
        "antigravity/auditor.py",
        "antigravity/monitor.py",
        "antigravity/dashboard.py",
        "antigravity/dependency_analyzer.py",
        "antigravity/context_manager.py"
    ]
    
    detector.scan_files(test_files)
    
    # è·å–å˜æ›´æ‘˜è¦
    summary = detector.get_change_summary()
    
    print(f"\nğŸ“Š Change Summary:")
    print(f"  Changed: {len(summary['changed'])} files")
    print(f"  New: {len(summary['new'])} files")
    print(f"  Deleted: {len(summary['deleted'])} files")
    print(f"  Unchanged: {len(summary['unchanged'])} files")
    print(f"  Total changes: {summary['total_changes']}")
    
    # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å¢é‡åŒæ­¥
    if detector.should_use_incremental_sync():
        print(f"\nâœ… Recommend incremental sync (â‰¤3 changes)")
    else:
        print(f"\nğŸ“Š Recommend full sync ({summary['total_changes']} changes)")
    
    # ä¿å­˜å¿«ç…§
    detector.save_snapshot({"test": "initial_scan"})
    
    print(f"\nâœ… Test complete!")
